"""
ReAct Agent æ ¸å¿ƒå¼•æ“
å®ç°åŸºäº Reasoning + Acting æ¡†æ¶çš„å¤šæ­¥æ¨ç†
"""
import json
import re
from typing import List, Dict, Any, Optional
from hpf_audit.skills.base import BaseSkill


class ReActAgent:
    """ReAct Agent å¼•æ“"""
    
    def __init__(
        self,
        llm_client,
        skills: List[BaseSkill],
        max_iterations: int = 5,
        verbose: bool = True,
        schema_context: str = "",  # æ•°æ®åº“ Schema ä¸Šä¸‹æ–‡
        db_path: str = "./housing_provident_fund.db"  # æ–°å¢ï¼šæ•°æ®åº“è·¯å¾„
    ):
        """
        åˆå§‹åŒ– ReAct Agent
        
        Args:
            llm_client: LLM å®¢æˆ·ç«¯ï¼ˆæ”¯æŒ generate æ–¹æ³•ï¼‰
            skills: å¯ç”¨çš„ Skills åˆ—è¡¨
            max_iterations: æœ€å¤§æ¨ç†è½®æ•°
            verbose: æ˜¯å¦æ‰“å°æ¨ç†è¿‡ç¨‹
            schema_context: æ•°æ®åº“ Schema æè¿°ï¼ˆå¯é€‰ï¼‰
            db_path: æ•°æ®åº“è·¯å¾„ï¼ˆç”¨äºå‘é‡æ£€ç´¢ï¼‰
        """
        self.llm = llm_client
        self.skills = {skill.name: skill for skill in skills}
        self.max_iterations = max_iterations
        self.verbose = verbose
        self.schema_context = schema_context
        
        # æ–°å¢ï¼šåˆå§‹åŒ–å‘é‡æ£€ç´¢å™¨ï¼ˆç”¨äº Skill è¯­ä¹‰æ£€ç´¢ï¼‰
        self.retriever = None
        try:
            from hpf_audit.skills.vector_retriever import VectorRetriever
            self.retriever = VectorRetriever(db_path)
            if self.verbose:
                print(f"âœ… Skill è¯­ä¹‰æ£€ç´¢å·²å¯ç”¨")
        except Exception as e:
            if self.verbose:
                print(f"âš ï¸ Skill è¯­ä¹‰æ£€ç´¢ä¸å¯ç”¨: {e}")

    
    def run(self, user_query: str) -> Dict[str, Any]:
        """
        æ‰§è¡Œ ReAct æ¨ç†å¾ªç¯
        
        Args:
            user_query: ç”¨æˆ·é—®é¢˜
        
        Returns:
            {
                "answer": æœ€ç»ˆç­”æ¡ˆ,
                "reasoning_chain": æ¨ç†é“¾,
                "iterations": å®é™…è¿­ä»£æ¬¡æ•°
            }
        """
        reasoning_chain = []
        tool_call_history = []  # è®°å½•å·¥å…·è°ƒç”¨å†å² [(tool_name, tool_input), ...]
        
        if self.verbose:
            print(f"\n{'='*60}")
            print(f"ç”¨æˆ·é—®é¢˜: {user_query}")
            print(f"{'='*60}\n")
            
        # 0. é¢„å…ˆæ£€ç´¢ç›¸å…³ Skills (åªæ£€ç´¢ä¸€æ¬¡)
        relevant_skills = self._find_relevant_skills(user_query, top_k=3)
        
        for i in range(self.max_iterations):
            if self.verbose:
                print(f"--- ç¬¬ {i+1} è½®æ¨ç† ---")
            
            # 1. æ„å»º Prompt
            prompt = self._build_prompt(user_query, reasoning_chain, relevant_skills)
            
            # æ‰“å° Promptï¼ˆåœ¨ verbose æ¨¡å¼ä¸‹ï¼‰
            if self.verbose:
                print(f"ğŸ“ æ„å»ºçš„ Prompt (å‰500å­—ç¬¦):")
                print(prompt[:500] + "..." if len(prompt) > 500 else prompt)
                print()
            
            # 2. LLM æ¨ç†
            response = self.llm.generate(prompt)
            
            if self.verbose:
                print(f"LLM å“åº”:\n{response}\n")
            
            # 3. è§£æå“åº”
            parsed = self._parse_response(response)
            
            # 4. åˆ¤æ–­æ˜¯å¦å¾—å‡ºæœ€ç»ˆç­”æ¡ˆ
            if parsed["type"] == "final_answer":
                reasoning_chain.append({
                    "iteration": i + 1,
                    "thought": parsed.get("thought", ""),
                    "type": "final_answer",
                    "answer": parsed["content"]
                })
                
                return {
                    "answer": parsed["content"],
                    "reasoning_chain": reasoning_chain,
                    "iterations": i + 1
                }
            
            # 5. æ‰§è¡Œå·¥å…·è°ƒç”¨
            if parsed["type"] == "action":
                tool_name = parsed["tool"]
                tool_input = parsed["input"]
                
                # æ£€æµ‹é‡å¤è°ƒç”¨
                current_call = (tool_name, json.dumps(tool_input, sort_keys=True))
                if current_call in tool_call_history:
                    # æ£€æµ‹åˆ°é‡å¤è°ƒç”¨ï¼Œå¼ºåˆ¶ç»™å‡ºæœ€ç»ˆç­”æ¡ˆ
                    summary = self._generate_summary_from_history(reasoning_chain, user_query)
                    reasoning_chain.append({
                        "iteration": i + 1,
                        "thought": f"æ£€æµ‹åˆ°é‡å¤è°ƒç”¨å·¥å…· {tool_name}ï¼Œæ ¹æ®å·²æ”¶é›†çš„ä¿¡æ¯ç»™å‡ºæœ€ç»ˆç­”æ¡ˆ",
                        "type": "final_answer",
                        "answer": summary
                    })
                    
                    if self.verbose:
                        print(f"âš ï¸ æ£€æµ‹åˆ°é‡å¤è°ƒç”¨ï¼Œè‡ªåŠ¨ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ\n")
                    
                    return {
                        "answer": summary,
                        "reasoning_chain": reasoning_chain,
                        "iterations": i + 1,
                        "recommended_skills": relevant_skills
                    }
                
                tool_call_history.append(current_call)
                
                observation = self._execute_tool(tool_name, tool_input)
                
                reasoning_chain.append({
                    "iteration": i + 1,
                    "thought": parsed.get("thought", ""),
                    "type": "action",
                    "action": tool_name,
                    "action_input": tool_input,
                    "observation": observation
                })
                
                if self.verbose:
                    print(f"å·¥å…·æ‰§è¡Œç»“æœ:\n{json.dumps(observation, ensure_ascii=False, indent=2)}\n")
            else:
                # è§£æå¤±è´¥ï¼Œè®°å½•å¹¶ç»§ç»­
                reasoning_chain.append({
                    "iteration": i + 1,
                    "type": "parse_error",
                    "raw_response": response
                })
        
        # è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°ï¼Œè‡ªåŠ¨ç”Ÿæˆæ€»ç»“
        summary = self._generate_summary_from_history(reasoning_chain, user_query)
        return {
            "answer": summary,
            "reasoning_chain": reasoning_chain,
            "iterations": self.max_iterations
        }

    
    def run_stream(self, user_query: str):
        """
        æ‰§è¡Œ ReAct æ¨ç†å¾ªç¯ï¼ˆæµå¼ç‰ˆæœ¬ï¼‰
        æ¯è½®æ¨ç†å yield ç»“æœ
        
        Args:
            user_query: ç”¨æˆ·é—®é¢˜
        
        Yields:
            æ¯è½®æ¨ç†çš„ç»“æœå­—å…¸
        """
        reasoning_chain = []
        
        if self.verbose:
            print(f"\n{'='*60}")
            print(f"ç”¨æˆ·é—®é¢˜: {user_query}")
            print(f"{'='*60}\n")
        
        # å‘é€å¼€å§‹äº‹ä»¶
        yield {
            "type": "start",
            "query": user_query,
            "max_iterations": self.max_iterations
        }
        
        # 0. é¢„å…ˆæ£€ç´¢ç›¸å…³ Skills
        relevant_skills = self._find_relevant_skills(user_query, top_k=3)
        
        # å»ºç«‹ Skill ID -> Score çš„æ˜ å°„
        skill_scores = {}
        if relevant_skills:
            for skill in relevant_skills:
                if skill.get("skill_id"):
                    skill_scores[skill["skill_id"]] = skill["score"]
        
        # å‘é€æ¨è Skills äº‹ä»¶
        if relevant_skills:
            yield {
                "type": "recommended_skills",
                "skills": relevant_skills
            }
        
        for i in range(self.max_iterations):
            if self.verbose:
                print(f"--- ç¬¬ {i+1} è½®æ¨ç† ---")
            
            # å‘é€æ¨ç†å¼€å§‹äº‹ä»¶
            yield {
                "type": "iteration_start",
                "iteration": i + 1
            }
            
            # 1. æ„å»º Prompt
            prompt = self._build_prompt(user_query, reasoning_chain, relevant_skills)
            
            # æ‰“å° Promptï¼ˆåœ¨ verbose æ¨¡å¼ä¸‹ï¼‰
            if self.verbose:
                print(f"ğŸ“ æ„å»ºçš„ Prompt (å‰500å­—ç¬¦):")
                print(prompt[:500] + "..." if len(prompt) > 500 else prompt)
                print()
            
            # 2. LLM æ¨ç†
            response = self.llm.generate(prompt)
            
            if self.verbose:
                print(f"LLM å“åº”:\n{response}\n")
            
            # 3. è§£æå“åº”
            parsed = self._parse_response(response)
            
            # 4. åˆ¤æ–­æ˜¯å¦å¾—å‡ºæœ€ç»ˆç­”æ¡ˆ
            if parsed["type"] == "final_answer":
                step = {
                    "iteration": i + 1,
                    "thought": parsed.get("thought", ""),
                    "type": "final_answer",
                    "answer": parsed["content"]
                }
                reasoning_chain.append(step)
                
                # å‘é€æœ€ç»ˆç­”æ¡ˆ
                yield {
                    "type": "final_answer",
                    "data": step
                }
                
                # å‘é€å®Œæˆäº‹ä»¶
                yield {
                    "type": "complete",
                    "answer": parsed["content"],
                    "reasoning_chain": reasoning_chain,
                    "iterations": i + 1
                }
                return
            
            # 5. æ‰§è¡Œå·¥å…·è°ƒç”¨
            if parsed["type"] == "action":
                tool_name = parsed["tool"]
                tool_input = parsed["input"]
                
                # è·å–è¯¥å·¥å…·çš„æ¨èåˆ†æ•°ï¼ˆå¦‚æœæœ‰ï¼‰
                tool_score = skill_scores.get(tool_name)
                
                # å‘é€å·¥å…·è°ƒç”¨å¼€å§‹
                yield {
                    "type": "tool_call_start",
                    "iteration": i + 1,
                    "tool": tool_name,
                    "score": tool_score,  # æ·»åŠ åˆ†æ•°
                    "input": tool_input
                }
                
                observation = self._execute_tool(tool_name, tool_input)
                
                step = {
                    "iteration": i + 1,
                    "thought": parsed.get("thought", ""),
                    "type": "action",
                    "action": tool_name,
                    "score": tool_score,  # æ·»åŠ åˆ†æ•°åˆ° step
                    "action_input": tool_input,
                    "observation": observation
                }
                reasoning_chain.append(step)
                
                if self.verbose:
                    print(f"å·¥å…·æ‰§è¡Œç»“æœ:\n{json.dumps(observation, ensure_ascii=False, indent=2)}\n")
                
                # å‘é€å·¥å…·æ‰§è¡Œç»“æœ
                yield {
                    "type": "tool_call_complete",
                    "data": step
                }
            else:
                # è§£æå¤±è´¥
                step = {
                    "iteration": i + 1,
                    "type": "parse_error",
                    "raw_response": response
                }
                reasoning_chain.append(step)
                
                yield {
                    "type": "error",
                    "data": step
                }
        
        # è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°
        final_result = {
            "answer": "æŠ±æ­‰ï¼Œç»è¿‡å¤šè½®æ¨ç†ä»æœªå¾—å‡ºç»“è®ºã€‚è¯·å°è¯•ç®€åŒ–é—®é¢˜æˆ–æä¾›æ›´å¤šä¿¡æ¯ã€‚",
            "reasoning_chain": reasoning_chain,
            "iterations": self.max_iterations
        }
        
        yield {
            "type": "complete",
            **final_result
        }

    
    
    def _build_prompt(self, user_query: str, history: List[Dict], recommended_skills_list: List[Dict] = None) -> str:
        """æ„å»º Promptï¼Œä½¿ç”¨è¯­ä¹‰æ£€ç´¢æ¨è Skill"""
        
        # å·¥å…·æè¿°
        tools_desc = self._format_tools_description()
        
        # âœ¨ æ–°å¢ï¼šè¯­ä¹‰æ£€ç´¢æ¨è Skills
        recommended_skills = ""
        # relevant = self._find_relevant_skills(user_query, top_k=3)  <- ç§»é™¤å†…éƒ¨è°ƒç”¨
        if recommended_skills_list:
            recommended_skills = "\n**æ¨èä½¿ç”¨ä»¥ä¸‹ Skills**ï¼ˆæ ¹æ®é—®é¢˜è¯­ä¹‰ç›¸ä¼¼åº¦æ’åºï¼‰:\n"
            for i, skill in enumerate(recommended_skills_list, 1):
                # âœ¨ å¦‚æœæ˜¯å…³è”æŠ€èƒ½ï¼Œæ·»åŠ æ ‡è®°
                tag = "[å…³è”æ¨è] " if skill.get("is_related") else ""
                score_display = "ç›¸å…³" if skill.get("is_related") else f"ç›¸ä¼¼åº¦: {skill['score']:.2f}"
                
                recommended_skills += f"{i}. **{tag}{skill['name']}** ({score_display})\n"
                recommended_skills += f"   ID: `{skill['skill_id']}`\n"
                recommended_skills += f"   åŠŸèƒ½: {skill['description']}\n\n"
        
        # å†å²è®°å½•
        history_text = self._format_history(history)
        
        # è®¡ç®—å½“å‰è½®æ¬¡
        current_iteration = len(history) + 1
        max_iterations = self.max_iterations
        
        prompt = f"""ä½ æ˜¯å…¬ç§¯é‡‘ä¸šåŠ¡å®¡è®¡ä¸“å®¶ã€‚è¯·æŒ‰ç…§ ReAct æ¡†æ¶æ€è€ƒå’Œè¡ŒåŠ¨ã€‚

å¯ç”¨å·¥å…·ï¼š
{tools_desc}
{recommended_skills}
ç”¨æˆ·é—®é¢˜ï¼š{user_query}

**é‡è¦è¯´æ˜**ï¼š
1. **ä¼˜å…ˆä½¿ç”¨æ¨èçš„ Skills**ï¼šä¸Šæ–¹åˆ—å‡ºçš„ Skills æ˜¯æ ¹æ®é—®é¢˜è¯­ä¹‰åŒ¹é…åº¦æ¨èçš„ï¼Œä¼˜å…ˆè€ƒè™‘ä½¿ç”¨
2. **æ•°æ®æŸ¥è¯¢æµç¨‹**ï¼š
   - å¦‚æœéœ€è¦ç»Ÿè®¡åˆ†ææ•°æ®ï¼ˆå¦‚"æœ‰å¤šå°‘ä¸ªæ­£å¸¸è´¦æˆ·"ï¼‰ï¼Œå¿…é¡»å…ˆç”¨ safe_query æŸ¥è¯¢å®é™…æ•°æ®
   - ç„¶åç”¨ data_analysis åˆ†ææŸ¥è¯¢ç»“æœ
   - ä¾‹å¦‚ï¼šæŸ¥è¯¢æ­£å¸¸è´¦æˆ· â†’ safe_query("SELECT deposit_status FROM t_individual_info") â†’ data_analysis(åˆ†æç»“æœ)

2. **é”™è¯¯å¤„ç†**ï¼š
   - å¦‚æœå·¥å…·æ‰§è¡Œå¤±è´¥ï¼Œä»”ç»†é˜…è¯»é”™è¯¯ä¿¡æ¯å¹¶è°ƒæ•´ç­–ç•¥
   - å¸¸è§é”™è¯¯ï¼šå‚æ•°ç±»å‹é”™è¯¯ã€SQLè¯­æ³•é”™è¯¯ã€æ•°æ®æ ¼å¼ä¸åŒ¹é…
   - é‡åˆ°é”™è¯¯æ—¶ï¼Œè§£é‡Šé”™è¯¯åŸå› å¹¶å°è¯•ä¿®æ­£ï¼Œæˆ–å‘ç”¨æˆ·è¯´æ˜é—®é¢˜

3. **å·¥å…·ä½¿ç”¨è§„åˆ™**ï¼š
   - data_analysis å·¥å…·éœ€è¦å®é™…æ•°æ®ï¼Œä¸èƒ½ä¼ é€’å­—ç¬¦ä¸²æè¿°æˆ–å­—æ®µå
   - safe_query ç”¨äºä»æ•°æ®åº“è·å–æ•°æ®ï¼Œæ”¯æŒ SQLite è¯­æ³•
   - å…¶ä»–å®¡è®¡å·¥å…·ç”¨äºç‰¹å®šçš„é£é™©æ£€æŸ¥

4. **å¸¸è§é—®é¢˜ç±»å‹æ˜ å°„**ï¼š
   - "æœ‰å¤šå°‘ä¸ªXX" â†’ å…ˆ safe_query ç»Ÿè®¡ï¼Œå† data_analysis åˆ†æ
   - "åˆ†ææŸäºº/æŸè´¦æˆ·" â†’ è°ƒç”¨ withdrawal_audit æˆ– loan_compliance
   - "æ£€æŸ¥è´­æˆ¿/è´·æ¬¾/æå–" â†’ å¯¹åº”çš„å®¡è®¡å·¥å…·
   - "æŸ¥æ‰¾å¼‚å¸¸" â†’ ç›¸å…³æ£€æŸ¥å·¥å…·

5. **ä½•æ—¶ç»™å‡ºæœ€ç»ˆç­”æ¡ˆï¼ˆCRITICALï¼‰**ï¼š
   - å½“ä½ å·²ç»æ”¶é›†äº†è¶³å¤Ÿçš„ä¿¡æ¯æ¥å›ç­”ç”¨æˆ·é—®é¢˜æ—¶ï¼Œå¿…é¡»ç«‹å³è¾“å‡º FinalAnswer
   - å¯¹äºç»Ÿè®¡é—®é¢˜ï¼šå®Œæˆæ•°æ®æŸ¥è¯¢å’Œåˆ†æåå°±åº”è¯¥ç»™å‡ºç»“è®º
   - å¯¹äº"åˆ†ææŸäºº"çš„é—®é¢˜ï¼šå®Œæˆ 2-3 ä¸ªä¸»è¦ç»´åº¦çš„æ£€æŸ¥åå°±åº”è¯¥ç»™å‡ºç»“è®º
   - å¦‚æœé‡åˆ°æ— æ³•è§£å†³çš„é”™è¯¯ï¼Œå‘ç”¨æˆ·è¯´æ˜é—®é¢˜å¹¶ç»™å‡ºå»ºè®®
   - ä¸è¦é‡å¤è°ƒç”¨ç›¸åŒçš„å·¥å…·æ£€æŸ¥å·²ç»æ£€æŸ¥è¿‡çš„å†…å®¹
   - å½“å‰å·²è¿›è¡Œ {current_iteration}/{max_iterations} è½®æ¨ç†ï¼Œè¯·æ³¨æ„æ¨ç†æ•ˆç‡

6. **ä¸¥æ ¼çš„è¾“å‡ºæ ¼å¼**ï¼š

å¦‚æœéœ€è¦è°ƒç”¨å·¥å…·ï¼š
Thought: [ä½ çš„æ€è€ƒè¿‡ç¨‹ï¼Œè¯´æ˜ä¸ºä»€ä¹ˆé€‰æ‹©è¿™ä¸ªå·¥å…·]
Action: [å·¥å…·åç§°]
ActionInput: {{"param": "value"}}

å¦‚æœå·²æœ‰è¶³å¤Ÿä¿¡æ¯å›ç­”é—®é¢˜ï¼ˆå¿…é¡»ä¸¥æ ¼æŒ‰æ­¤æ ¼å¼ï¼‰ï¼š
Thought: [æ€»ç»“å·²æ”¶é›†çš„ä¿¡æ¯ï¼Œè¯´æ˜ä¸ºä»€ä¹ˆç°åœ¨å¯ä»¥ç»™å‡ºç­”æ¡ˆ]
FinalAnswer: [ä½ çš„æœ€ç»ˆç­”æ¡ˆï¼ŒåŒ…å«å®Œæ•´çš„åˆ†æç»“è®º]

**æ•°æ®åº“è¡¨ç»“æ„å‚è€ƒ**ï¼š
- GR_JC_JBXX: ä¸ªäººè´¦æˆ·ä¿¡æ¯ï¼ˆGRJCZT: ç¼´å­˜çŠ¶æ€ï¼‰
- GR_JC_MX: ä¸šåŠ¡æµæ°´æ˜ç»†
- GR_DK_HT: è´·æ¬¾ç”³è¯·ä¿¡æ¯
- DW_JC_JBXX: å•ä½åŸºç¡€ä¿¡æ¯

å†å²è®°å½•ï¼š
{history_text}

ç°åœ¨å¼€å§‹æ¨ç†ï¼ˆç¬¬ {current_iteration} è½®ï¼‰ï¼š"""
        
        return prompt

    
    def _find_relevant_skills(self, query: str, top_k: int = 3) -> List[Dict]:
        """
        é€šè¿‡è¯­ä¹‰æ£€ç´¢æ‰¾åˆ°ç›¸å…³ Skill
        
        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
            top_k: è¿”å›æ•°é‡
        
        Returns:
            [
                {
                    "skill_id": "é€¾æœŸ_è´·æ¬¾_ç›‘æµ‹_a1b2",
                    "name": "é€¾æœŸè´·æ¬¾é£é™©ç›‘æµ‹",
                    "description": "...",
                    "score": 0.85,
                    "metadata": {...}
                },
                ...
            ]
        """
        if not self.retriever:
            return []
        
        try:
            import json
            # æ£€ç´¢ skill_catalog åˆ†ç±»
            # æ£€ç´¢ skill_catalog åˆ†ç±»
            skill_hits = self.retriever.search(
                query, 
                top_k=top_k, 
                filter={"category": "skill_catalog"}
            )
            
            if self.verbose:
                print(f"DEBUG: VectorRetriever returned {len(skill_hits)} hits for query '{query}'")
            
            
            results = []
            for hit in skill_hits:
                try:
                    metadata_str = hit.get('metadata', '{}') or '{}'
                    # Handle case where metadata might already be a dict
                    if isinstance(metadata_str, dict):
                        metadata = metadata_str
                    else:
                        metadata = json.loads(metadata_str)
                        
                    if self.verbose:
                        print(f"DEBUG: Processing hit: {hit.get('title')} (Score: {hit.get('score')})")
                        
                    results.append({
                        "skill_id": metadata.get('skill_id'),
                        "name": hit['title'],
                        "description": hit['content'][:150],
                        "score": hit['score'],
                        "is_related": metadata.get('is_related', False), # âœ¨ ä¼ é€’å…³è”æ ‡è®°
                        "metadata": metadata
                    })
                except Exception as e:
                    if self.verbose:
                        print(f"DEBUG: Error parsing hit metadata: {e}")
                    continue
            
            return results
        except Exception as e:
            if self.verbose:
                print(f"âš ï¸ Skill è¯­ä¹‰æ£€ç´¢å¤±è´¥: {e}")
            return []
    
    def _format_tools_description(self) -> str:
        """æ ¼å¼åŒ–å·¥å…·æè¿°"""
        desc_list = []
        for name, skill in self.skills.items():
            desc_list.append(f"- {name}: {skill.description}")
        return "\n".join(desc_list)
    
    def _format_history(self, history: List[Dict]) -> str:
        """æ ¼å¼åŒ–å†å²è®°å½•"""
        if not history:
            return "(æ— )"
        
        lines = []
        for step in history:
            lines.append(f"ç¬¬{step['iteration']}è½®:")
            if step["type"] == "action":
                lines.append(f"  Thought: {step['thought']}")
                lines.append(f"  Action: {step['action']}")
                lines.append(f"  Observation: {json.dumps(step['observation'], ensure_ascii=False)}")
            lines.append("")
        
        return "\n".join(lines)
    
    def _parse_response(self, response: str) -> Dict[str, Any]:
        """
        è§£æ LLM å“åº”
        """
        result = {
            "type": "unknown",
            "thought": "",
            "raw": response
        }
        
        lines = response.strip().split('\n')
        
        # 1. æå– Thought
        for line in lines:
            if line.strip().startswith("Thought:"):
                result["thought"] = line.replace("Thought:", "").strip()
                break
        
        # 2. æå– FinalAnswer
        if "FinalAnswer:" in response:
            result["type"] = "final_answer"
            # æ‰¾åˆ° FinalAnswer ä¹‹åçš„æ‰€æœ‰å†…å®¹
            try:
                content = response.split("FinalAnswer:", 1)[1].strip()
                result["content"] = content
            except IndexError:
                result["content"] = ""
            return result
            
        # 3. æå– Action å’Œ ActionInput
        action_match = re.search(r"Action:\s*(.+)", response)
        if action_match:
            result["type"] = "action"
            result["tool"] = action_match.group(1).strip()
            
            # å°è¯•æå– ActionInputï¼Œæ”¯æŒå¤šè¡Œå’Œ markdown
            # å…ˆæ‰¾ ActionInput: æ ‡è®°
            input_start_match = re.search(r"ActionInput:\s*(.*)", response, re.DOTALL)
            input_data = {}
            
            if input_start_match:
                raw_input = input_start_match.group(1).strip()
                
                # æƒ…å†µA: ```json ... ``` åŒ…è£¹
                json_block_match = re.search(r"```(?:json)?\s*(.*?)\s*```", raw_input, re.DOTALL)
                if json_block_match:
                    json_str = json_block_match.group(1).strip()
                    try:
                        input_data = json.loads(json_str)
                    except:
                        pass
                
                # æƒ…å†µB: ç›´æ¥æ˜¯ JSON å­—ç¬¦ä¸²ï¼Œå¯èƒ½è·¨è¡Œ
                if not input_data:
                    try:
                        # å°è¯•ç›´æ¥è§£æå‰©ä½™éƒ¨åˆ†
                        input_data = json.loads(raw_input)
                    except json.JSONDecodeError:
                        # å°è¯•é€è¡Œç´¯åŠ è§£æï¼ˆå¤„ç†åªæœ‰éƒ¨åˆ†æ˜¯ JSON çš„æƒ…å†µï¼‰
                        current_json = ""
                        for char in raw_input:
                            current_json += char
                            try:
                                if char == '}': # æœ‰å¯èƒ½æ˜¯ç»“å°¾
                                    input_data = json.loads(current_json)
                                    break
                            except:
                                continue
            
            # å¦‚æœå®åœ¨è§£æä¸å‡ºæ¥ï¼Œä¸” raw_input çœ‹èµ·æ¥åƒå­—å…¸å­—ç¬¦ä¸²ï¼ˆå•å¼•å·ï¼‰
            if not input_data and input_start_match:
                try:
                    import ast
                    # å±é™©æ“ä½œï¼Œä½†åœ¨å—æ§ç¯å¢ƒä¸‹ä½œä¸º fallback
                    val = ast.literal_eval(raw_input.split('\n')[0]) 
                    if isinstance(val, dict):
                        input_data = val
                except:
                    pass

            result["input"] = input_data
            return result
        
        # 4. éšå¼ FinalAnswer æ£€æµ‹
        summary_keywords = [
            'ç»¼åˆè¯„ä¼°', 'é£é™©è¯„ä¼°æ€»ç»“', 'åˆ†æç»“è®º', 'å®¡è®¡ç»“è®º', 
            'æœ€ç»ˆç»“è®º', 'æ€»ç»“å¦‚ä¸‹', 'è¯„ä¼°å¦‚ä¸‹', 'å·²å®Œæˆ', 'æ ¹æ®ä¸Šè¿°'
        ]
        if any(kw in response.lower() for kw in summary_keywords):
            result["type"] = "final_answer"
            # å»æ‰ Thought éƒ¨åˆ†
            if "Thought:" in response:
                result["content"] = response.split("Thought:")[-1].split('\n', 1)[-1].strip()
            else:
                result["content"] = response
            return result
            
        return result
    
    def _execute_tool(self, tool_name: str, tool_input: Dict) -> Dict[str, Any]:
        """æ‰§è¡Œå·¥å…·"""
        if tool_name not in self.skills:
            error_result = {
                "success": False,
                "error": f"å·¥å…· '{tool_name}' ä¸å­˜åœ¨",
                "available_tools": list(self.skills.keys()),
                "message": f"âŒ é”™è¯¯ï¼šå·¥å…· '{tool_name}' ä¸å­˜åœ¨ã€‚å¯ç”¨å·¥å…·ï¼š{', '.join(list(self.skills.keys()))}"
            }
            if self.verbose:
                print(f"âŒ å·¥å…·é”™è¯¯: {error_result['message']}")
            return error_result
        
        try:
            skill = self.skills[tool_name]
            result = skill.execute(**tool_input)
            
            # ç¡®ä¿ç»“æœåŒ…å«å¿…è¦çš„å­—æ®µ
            if not isinstance(result, dict):
                result = {"success": False, "error": "å·¥å…·è¿”å›æ ¼å¼é”™è¯¯", "raw_result": result}
            
            # å¦‚æœå·¥å…·æ‰§è¡Œå¤±è´¥ï¼Œå¢å¼ºé”™è¯¯ä¿¡æ¯
            if not result.get("success", True):  # é»˜è®¤è®¤ä¸ºæˆåŠŸï¼Œé™¤éæ˜ç¡®æ ‡è®°å¤±è´¥
                if self.verbose:
                    error_msg = result.get("message") or result.get("error", "æœªçŸ¥é”™è¯¯")
                    print(f"âŒ å·¥å…·æ‰§è¡Œå¤±è´¥: {tool_name} - {error_msg}")
            
            return result
        except Exception as e:
            import traceback
            error_detail = traceback.format_exc()
            
            error_result = {
                "success": False,
                "error": f"å·¥å…·æ‰§è¡Œå¼‚å¸¸: {str(e)}",
                "tool": tool_name,
                "input": tool_input,
                "traceback": error_detail,
                "message": f"âŒ å·¥å…· '{tool_name}' æ‰§è¡Œæ—¶å‘ç”Ÿå¼‚å¸¸ï¼š{str(e)}"
            }
            
            if self.verbose:
                print(f"âŒ å·¥å…·å¼‚å¸¸: {tool_name}")
                print(f"   è¾“å…¥å‚æ•°: {tool_input}")
                print(f"   å¼‚å¸¸ä¿¡æ¯: {str(e)}")
                print(f"   è¯¦ç»†å †æ ˆ:\n{error_detail}")
            
            return error_result
    
    def _generate_summary_from_history(self, history: List[Dict], user_query: str) -> str:
        """
        æ ¹æ®æ¨ç†å†å²è‡ªåŠ¨ç”Ÿæˆæ€»ç»“
        ç”¨äºåœ¨è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°æˆ–æ£€æµ‹åˆ°é‡å¤è°ƒç”¨æ—¶ç»™å‡ºæœ€ç»ˆç­”æ¡ˆ
        """
        if not history:
            return "æœªæ”¶é›†åˆ°ä»»ä½•ä¿¡æ¯ï¼Œæ— æ³•å›ç­”é—®é¢˜ã€‚"
        
        # æå–æ‰€æœ‰æˆåŠŸçš„å·¥å…·è°ƒç”¨ç»“æœ
        findings = []
        for step in history:
            if step.get("type") == "action" and "observation" in step:
                obs = step["observation"]
                tool = step["action"]
                
                # æå–å…³é”®ä¿¡æ¯
                if obs.get("success"):
                    data = obs.get("data", {})
                    message = obs.get("message", "")
                    
                    # æ ¹æ®ä¸åŒå·¥å…·ç±»å‹æå–ä¿¡æ¯
                    if "check_type" in data:
                        check_type = data.get("check_type", tool)
                        
                        # æ£€æŸ¥æ˜¯å¦æœ‰é£é™©å‘ç°
                        total_risk = (
                            data.get("total_risk_accounts", 0) or 
                            data.get("total_risk_loans", 0) or
                            data.get("total_activations", 0) or
                            data.get("total_operations", 0) or
                            0
                        )
                        
                        if total_risk > 0:
                            findings.append(f"âœ— {check_type}: {message}")
                        else:
                            findings.append(f"âœ“ {check_type}: æœªå‘ç°å¼‚å¸¸")
        
        if not findings:
            return "ç»è¿‡å¤šè½®æ£€æŸ¥ï¼Œæœªå‘ç°æ˜æ˜¾å¼‚å¸¸é£é™©ã€‚"
        
        # ç”Ÿæˆæ ¼å¼åŒ–çš„æ€»ç»“
        summary = f"æ ¹æ®å¯¹ã€Œ{user_query}ã€çš„å®¡è®¡åˆ†æï¼Œç»“æœå¦‚ä¸‹ï¼š\n\n"
        
        # åˆ†ç±»æ˜¾ç¤ºå‘ç°çš„é—®é¢˜å’Œæ­£å¸¸é¡¹
        risks = [f for f in findings if f.startswith("âœ—")]
        normals = [f for f in findings if f.startswith("âœ“")]
        
        if risks:
            summary += "**å‘ç°çš„é£é™©**ï¼š\n"
            for r in risks:
                summary += f"  {r}\n"
            summary += "\n"
        
        if normals:
            summary += "**æ­£å¸¸æ£€æŸ¥é¡¹**ï¼š\n"
            for n in normals:
                summary += f"  {n}\n"
        
        if not risks:
            summary += "\n**ç»¼åˆè¯„ä¼°**ï¼šæ‰€æœ‰æ£€æŸ¥é¡¹å‡æ­£å¸¸ï¼Œæœªå‘ç°é£é™©ã€‚"
        else:
            summary += "\n**ç»¼åˆè¯„ä¼°**ï¼šå‘ç°éƒ¨åˆ†é£é™©é¡¹ï¼Œå»ºè®®è¿›ä¸€æ­¥æ ¸æŸ¥ã€‚"
        
        return summary


# å…¼å®¹æ—§ä»£ç çš„åˆ«åå·²ç§»é™¤ï¼Œè¯·ç›´æ¥ä½¿ç”¨ LLMClient
