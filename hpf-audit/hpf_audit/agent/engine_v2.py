"""
LangGraph Agent (æ–°ç‰ˆ)
ä½¿ç”¨LangGraphæ›¿ä»£è‡ªç ”ReActå¼•æ“
"""
from typing import List, Dict, Any, Optional
import json
import os

try:
    from langgraph.prebuilt import create_react_agent
    from langchain_core.messages import SystemMessage, HumanMessage
    from langchain_openai import ChatOpenAI
    LANGGRAPH_AVAILABLE = True
except ImportError:
    LANGGRAPH_AVAILABLE = False
    print("Warning: LangGraph not available")

from hpf_audit.skills.langchain_tools import ALL_TOOLS


class LangGraphAgent:
    """åŸºäºLangGraphçš„Agentå¼•æ“"""
    
    def __init__(
        self,
        llm_client: Optional[Any] = None,  # ä¸ºäº†å…¼å®¹æ€§ä¿ç•™ï¼Œä½†ä¸ä½¿ç”¨
        max_iterations: int = 5,
        verbose: bool = True
    ):
        if not LANGGRAPH_AVAILABLE:
            raise ImportError("LangGraph is required. Run: pip install langgraph")
        
        self.verbose = verbose
        self.max_iterations = max_iterations
        
        # ä½¿ç”¨LangChainåŸç”ŸLLM (éœ€è¦æœ‰bind_toolsæ–¹æ³•)
        # ä»ç¯å¢ƒå˜é‡è¯»å–é…ç½®
        provider = os.getenv("DEFAULT_LLM_PROVIDER", "nvidia")
        api_key = None
        base_url = None
        model = None
        
        if provider == "nvidia":
            api_key = os.getenv("NVIDIA_API_KEY")
            base_url = os.getenv("NVIDIA_BASE_URL", "https://integrate.api.nvidia.com/v1")
            model = os.getenv("DEFAULT_LLM_MODEL", "meta/llama-3.1-70b-instruct")
        elif provider == "openai":
            api_key = os.getenv("OPENAI_API_KEY")
            base_url = os.getenv("OPENAI_BASE_URL")
            model = os.getenv("OPENAI_MODEL") or os.getenv("DEFAULT_LLM_MODEL", "gpt-4o-mini")
        elif provider == "deepseek":
            api_key = os.getenv("DEEPSEEK_API_KEY")
            base_url = os.getenv("DEEPSEEK_BASE_URL", "https://api.deepseek.com/v1")
            model = os.getenv("DEEPSEEK_MODEL", "deepseek-chat")
        elif provider == "cerebras":
            api_key = os.getenv("CEREBRAS_API_KEY")
            base_url = os.getenv("CEREBRAS_BASE_URL", "https://api.cerebras.ai/v1")
            model = os.getenv("CEREBRAS_MODEL", "llama3.1-70b")
        else:
            # é»˜è®¤ä½¿ç”¨nvidia
            api_key = os.getenv("NVIDIA_API_KEY")
            base_url = os.getenv("NVIDIA_BASE_URL", "https://integrate.api.nvidia.com/v1")
            model = os.getenv("DEFAULT_LLM_MODEL", "meta/llama-3.1-70b-instruct")
        
        # åˆ›å»ºChatOpenAIå®ä¾‹
        if not api_key:
            raise ValueError(f"æœªæ‰¾åˆ°{provider}çš„API Keyï¼Œè¯·æ£€æŸ¥.envæ–‡ä»¶")
        
        self.llm = ChatOpenAI(
            api_key=api_key,
            base_url=base_url,
            model=model,
            temperature=0.7
        )
        
        # åˆå§‹åŒ–å‘é‡å­˜å‚¨(ç”¨äºSkillæ¨è) - å¯é€‰
        self.vector_store = None
        try:
            from hpf_audit.knowledge.vector_store import VectorStoreManager
            self.vector_store = VectorStoreManager()
            if self.verbose:
                print("âœ… Skillå‘é‡æ£€ç´¢å·²å¯ç”¨")
        except Exception as e:
            if self.verbose:
                print(f"âš ï¸ Skillå‘é‡æ£€ç´¢æœªå¯ç”¨: {e}")
        
        # åˆ›å»ºAgent
        self.agent = self._create_agent()
    
    def _create_agent(self):
        """åˆ›å»ºLangGraph ReAct Agent"""
        
        # åˆ›å»ºAgent (ä¸ä½¿ç”¨state_modifier)
        agent = create_react_agent(
            model=self.llm,
            tools=ALL_TOOLS
        )
        
        return agent
    
    def run(self, user_query: str) -> Dict[str, Any]:
        """
        æ‰§è¡ŒAgentæ¨ç†
        
        Args:
            user_query: ç”¨æˆ·é—®é¢˜
        
        Returns:
            {
                "answer": "æœ€ç»ˆç­”æ¡ˆ",
                "reasoning_chain": [...],
                "iterations": 3
            }
        """
        # 1. æ¨èç›¸å…³Skills (å¯é€‰)
        recommended_skills = []
        if self.vector_store:
            try:
                recommended_skills = self.vector_store.search_skills(user_query, top_k=3)
                
                if self.verbose and recommended_skills:
                    print("\nğŸ” æ¨èSkills:")
                    for skill in recommended_skills:
                        print(f"  - {skill['name']} (ç›¸å…³åº¦: {skill['score']:.2f})")
            except Exception as e:
                if self.verbose:
                    print(f"âš ï¸ Skillæ¨èå¤±è´¥: {e}")
        
        # 2. æ‰§è¡ŒAgent (å°†system promptä½œä¸ºç¬¬ä¸€æ¡æ¶ˆæ¯)
        system_prompt = f"""ä½ æ˜¯å…¬ç§¯é‡‘ä¸šåŠ¡å®¡è®¡ä¸“å®¶ã€‚

**ä½ çš„ä»»åŠ¡**:
ç”¨æˆ·ä¼šæå‡ºå®¡è®¡ç›¸å…³é—®é¢˜ï¼Œä½ éœ€è¦ï¼š
1. ç†è§£é—®é¢˜å¹¶é€‰æ‹©åˆé€‚çš„å®¡è®¡å·¥å…·
2. è°ƒç”¨å·¥å…·è·å–æ•°æ®
3. åˆ†æç»“æœå¹¶ç»™å‡ºä¸“ä¸šå»ºè®®

**å¯ç”¨å·¥å…·**:
- withdrawal_audit: æå–å®¡è®¡
- loan_compliance: è´·æ¬¾åˆè§„
- internal_control_audit: å†…æ§å®¡è®¡
- organization_audit: å•ä½å®¡è®¡
- data_analysis: æ•°æ®åˆ†æ

**é‡è¦è§„åˆ™**:
- ä¼˜å…ˆä½¿ç”¨å·¥å…·è€Œéè‡†æµ‹
- æ¯æ¬¡åªè°ƒç”¨ä¸€ä¸ªå·¥å…·
- åŸºäºå·¥å…·è¿”å›çš„æ•°æ®ç»™å‡ºç»“è®º
- å¦‚æœå·¥å…·å¤±è´¥ï¼Œè§£é‡ŠåŸå› å¹¶å°è¯•å…¶ä»–æ–¹æ³•
- æ§åˆ¶åœ¨{self.max_iterations}è½®å†…å®Œæˆä»»åŠ¡
"""
        
        try:
            result = self.agent.invoke({
                "messages": [
                   SystemMessage(content=system_prompt),
                    HumanMessage(content=user_query)
                ]
            })
            
            # 3. æå–ç»“æœ
            messages = result.get("messages", [])
            answer = messages[-1].content if messages else "æœªè·å–åˆ°å›ç­”"
            
            return {
                "answer": answer,
                "reasoning_chain": self._extract_chain(messages),
                "iterations": len([m for m in messages if hasattr(m, 'type') and m.type == "ai"]),
                "recommended_skills": recommended_skills
            }
        except Exception as e:
            import traceback
            error_msg = f"Agentæ‰§è¡Œå¤±è´¥: {str(e)}\n{traceback.format_exc()}"
            if self.verbose:
                print(f"âŒ {error_msg}")
            
            return {
                "answer": f"æ‰§è¡Œå‡ºé”™: {str(e)}",
                "reasoning_chain": [],
                "iterations": 0,
                "error": error_msg
            }
    
    def _extract_chain(self, messages) -> List[Dict]:
        """ä»æ¶ˆæ¯ä¸­æå–æ¨ç†é“¾"""
        chain = []
        iteration = 0
        
        for msg in messages:
            msg_type = getattr(msg, 'type', 'unknown')
            
            if msg_type == "ai":
                iteration += 1
                chain.append({
                    "iteration": iteration,
                    "thought": msg.content,
                    "type": "reasoning"
                })
            elif msg_type == "tool":
                chain.append({
                    "iteration": iteration,
                    "type": "tool_result",
                    "tool": getattr(msg, 'name', 'unknown'),
                    "result": msg.content
                })
        
        return chain
