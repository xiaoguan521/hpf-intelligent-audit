#!/usr/bin/env python3
"""
AI Bronze Generator
è‡ªåŠ¨è¯»å– DuckDB ä¸­çš„ raw data (oracle_data schema)
å¹¶ä½¿ç”¨ LLM ç”Ÿæˆ dbt Bronze å±‚çš„ schema.yml å’Œ .sql æ–‡ä»¶
"""
import os
import sys
import yaml
import logging

# Add project root and hpf-common to path
# Script is at: hpf-platform/dbt_project/scripts/generate_bronze.py
# Root is at:   ../../../
project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), "../../.."))
sys.path.append(project_root)
sys.path.append(os.path.join(project_root, "hpf-common"))

from hpf_common.db import DBManager
from hpf_common.llm import LLMClient
from hpf_common.config import settings

# Setup Logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger("BronzeGen")

# Constants
# Models dir is at: ../models/bronze
DBT_BRONZE_DIR = os.path.abspath(os.path.join(os.path.dirname(__file__), "../models/bronze"))
SOURCE_SCHEMA = "oracle_data"  # DuckDB source schema

def get_table_metadata():
    # Calculate absolute path to DB based on project root
    # DB is located at: <project_root>/hpf-platform/data/warehouse.duckdb
    db_path = os.path.join(project_root, "hpf-platform/data/warehouse.duckdb")
    logger.info(f"Connecting to DuckDB: {db_path}")
    
    tables_meta = {}
    
    with DBManager.connect("duckdb", path=db_path, read_only=True) as conn:
        # è·å–æ‰€æœ‰è¡¨
        query_tables = f"""
            SELECT table_name 
            FROM information_schema.tables 
            WHERE table_schema = '{SOURCE_SCHEMA}'
        """
        tables = [row[0] for row in conn.execute(query_tables).fetchall()]
        
        # è·å–æ¯ä¸ªè¡¨çš„åˆ—
        for table in tables:
            query_cols = f"""
                SELECT column_name, data_type 
                FROM information_schema.columns 
                WHERE table_schema = '{SOURCE_SCHEMA}' AND table_name = '{table}'
            """
            columns = conn.execute(query_cols).fetchall()
            tables_meta[table] = [{"name": c[0], "type": c[1]} for c in columns]
            
    return tables_meta

def generate_dbt_files(table_name, columns, llm_client):
    """
    ä½¿ç”¨ LLM ç”Ÿæˆ dbt æ–‡ä»¶å†…å®¹
    1. schema.yml ç‰‡æ®µ (Table description)
    2. .sql æ–‡ä»¶åå’Œå†…å®¹
    """
    logger.info(f"Generating content for table: {table_name}")
    
    prompt = f"""
    æˆ‘æ˜¯ä¸€ä¸ª dbt å·¥ç¨‹å¸ˆã€‚æˆ‘æœ‰ä¸€ä¸ªåŸå§‹è¡¨ `{SOURCE_SCHEMA}.{table_name}`ã€‚
    åˆ—ä¿¡æ¯å¦‚ä¸‹:
    {columns}
    
    è¯·å¸®æˆ‘å®Œæˆä¸¤ä¸ªä»»åŠ¡:
    
    Task 1: ä¸ºè¯¥è¡¨ç”Ÿæˆä¸€ä¸ªåˆç†çš„ dbt Bronze å±‚æ–‡ä»¶å (é€šå¸¸æ˜¯ src_xxx.sql)ã€‚
    Task 2: ä¸ºè¯¥è¡¨ç”Ÿæˆä¸­æ–‡æè¿° (description)ã€‚
    Task 3: ç”Ÿæˆè¯¥è¡¨çš„ dbt SQL ä»£ç  (å¾ˆç®€å•, å°±æ˜¯ select * from source)ã€‚
    
    è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹ JSON æ ¼å¼è¿”å› (ä¸è¦åŒ…å« Markdown ä»£ç å—):
    {{
        "filename": "src_example.sql",
        "description": "è¿™æ˜¯ç¤ºä¾‹è¡¨çš„ä¸­æ–‡æè¿°",
        "sql_content": "select * from {{ source('oracle_data', 'EXAMPLE_TABLE') }}"
    }}
    """
    
    try:
        # ä½¿ç”¨ json mode æˆ–è€…æ˜¯ç®€å•çš„ parse
        messages = [{"role": "user", "content": prompt}]
        response = llm_client.chat(messages)
        
        # ç®€å•çš„æ¸…æ´—ï¼Œé˜²æ­¢ LLM è¿”å› markdown block
        clean_resp = response.replace("```json", "").replace("```", "").strip()
        import json
        return json.loads(clean_resp)
        
    except Exception as e:
        logger.warning(f"LLM generation failed for {table_name}: {e}. Using fallback template.")
        # Fallback template
        return {
            "filename": f"src_{table_name.lower()}.sql",
            "description": f"Source table {table_name} from oracle_data",
            "sql_content": f"select * from {{{{ source('{SOURCE_SCHEMA}', '{table_name}') }}}}"
        }

def main():
    if not os.path.exists(DBT_BRONZE_DIR):
        os.makedirs(DBT_BRONZE_DIR)
        
    # 1. è·å–å…ƒæ•°æ®
    try:
        tables_meta = get_table_metadata()
    except Exception as e:
        logger.error(f"Failed to get metadata: {e}")
        return

    if not tables_meta:
        logger.warning(f"No tables found in schema '{SOURCE_SCHEMA}'. Initialize mock data first?")
        return
        
    logger.info(f"Found {len(tables_meta)} tables: {list(tables_meta.keys())}")
    
    # 2. åˆå§‹åŒ– LLM
    llm = LLMClient()
    
    # 3. å‡†å¤‡ schema.yml ç»“æ„
    schema_yaml = {
        "version": 2,
        "sources": [{
            "name": SOURCE_SCHEMA,
            "schema": SOURCE_SCHEMA,
            "tables": []
        }]
    }
    
    # 4. éå†è¡¨ç”Ÿæˆæ–‡ä»¶
    for table_name, cols in tables_meta.items():
        result = generate_dbt_files(table_name, cols, llm)
        if not result:
            continue
            
        # Add to schema.yaml
        table_def = {
            "name": table_name,
            "description": result['description']
        }
        schema_yaml['sources'][0]['tables'].append(table_def)
        
        # Write .sql file
        file_path = os.path.join(DBT_BRONZE_DIR, result['filename'])
        with open(file_path, 'w') as f:
            f.write(result['sql_content'])
        logger.info(f"Created file: {result['filename']}")
        
    # 5. Write schema.yml
    schema_path = os.path.join(DBT_BRONZE_DIR, "schema.yml")
    with open(schema_path, 'w') as f:
        yaml.dump(schema_yaml, f, allow_unicode=True, sort_keys=False)
    logger.info(f"Updated schema.yml at {schema_path}")
    
    logger.info("ğŸ‰ AI Bronze Generation Complete!")

if __name__ == "__main__":
    main()
