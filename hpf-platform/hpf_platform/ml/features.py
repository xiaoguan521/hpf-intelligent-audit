"""
ç‰¹å¾å·¥ç¨‹ - ä» DuckDB åŠ è½½ç‰¹å¾æ•°æ®
"""
import duckdb
import pandas as pd
import numpy as np
from pathlib import Path
from typing import Tuple


def load_features(
    duckdb_path: str, 
    table_name: str = "fct_loan_features",
    schema: str = "analytics"
) -> pd.DataFrame:
    """
    ä» DuckDB åŠ è½½ ML ç‰¹å¾
    
    Args:
        duckdb_path: DuckDB æ•°æ®åº“è·¯å¾„
        table_name: ç‰¹å¾è¡¨å (dbt gold å±‚è¡¨)
        schema: æ•°æ®åº“ schema
    
    Returns:
        ç‰¹å¾ DataFrame
    
    Example:
        >>> df = load_features("../data/warehouse.duckdb")
        >>> df.head()
    """
    conn = duckdb.connect(duckdb_path, read_only=True)
    
    try:
        query = f"SELECT * FROM {schema}.{table_name}"
        df = conn.execute(query).df()
        
        # --- Preprocessing ---
        print("ğŸ§¹ Preprocessing features...")
        
        # 1. Drop IDs and Dates (non-features)
        drop_cols = ['contract_id', 'loan_start_date']
        
        # 2. Drop Leakage (loan_status implies target)
        # å…³é”®ä¿®æ­£ï¼šå¿…é¡»ç§»é™¤æ‰€æœ‰"æœªæ¥"æˆ–"ç»“æœæ€§"æŒ‡æ ‡ï¼Œåªä¿ç•™"ç”³è¯·æ—¶"ç‰¹å¾
        # overdue_count å’Œ total_repayment_periods éƒ½æ˜¯åŸæ¥ç”¨æ¥å®šä¹‰ Label çš„ï¼Œä¸èƒ½åš Feature
        leakage_cols = ['loan_status', 'overdue_count', 'total_repayment_periods', 'actual_repayment_date', 'has_overdue_history_flag']
        
        for col in leakage_cols:
            if col in df.columns:
                drop_cols.append(col)
            
        df = df.drop(columns=[c for c in drop_cols if c in df.columns])
        
        # 3. Simple Encoding for Categorical
        # Gender: M->0, F->1, U->2
        if 'gender' in df.columns:
            df['gender'] = df['gender'].map({'M': 0, 'F': 1, 'U': 2}).fillna(2)
        
        # Occupation: Encode based on stability (lower number = more stable)
        if 'occupation' in df.columns:
            occupation_map = {
                'civil_servant': 0,  # Most stable
                'teacher': 1,
                'doctor': 2,
                'engineer': 3,
                'worker': 4,
                'business_owner': 5,
                'freelancer': 6      # Least stable
            }
            df['occupation'] = df['occupation'].map(occupation_map).fillna(4)
        
        # Encode new categorical features
        if 'dti_category' in df.columns:
            df['dti_category'] = df['dti_category'].map({'low_risk': 0, 'medium_risk': 1, 'high_risk': 2}).fillna(0)
        
        if 'age_group' in df.columns:
            df['age_group'] = df['age_group'].map({'young': 0, 'prime': 1, 'mature': 2, 'senior': 3}).fillna(1)
        
        if 'income_level' in df.columns:
            df['income_level'] = df['income_level'].map({'low_income': 0, 'middle_income': 1, 'high_income': 2}).fillna(1)
        
        if 'loan_duration_type' in df.columns:
            df['loan_duration_type'] = df['loan_duration_type'].map({'short_term': 0, 'long_term': 1, 'ultra_long': 2}).fillna(0)
            
        # 4. Feature Engineering: Debt-to-Income Ratio (DTI)
        # Avoid division by zero
        if 'loan_amount' in df.columns and 'monthly_income' in df.columns:
            df['dti_ratio'] = df['loan_amount'] / (df['monthly_income'] + 1.0)
            
            # Cross feature: age * dti interaction
            if 'age' in df.columns:
                df['age_dti_interaction'] = df['age'] * df['dti_ratio']
            
            # Log transform income to compress extreme values
            df['log_income'] = np.log1p(df['monthly_income'])
            
            # === æ–°å¢é«˜ä»·å€¼ç‰¹å¾ï¼ˆæå‡ F1-Scoreï¼‰ ===
            
            # 1. æ”¶å…¥ç¨³å®šæ€§æŒ‡æ ‡ï¼ˆåå‘ DTIï¼‰
            df['income_loan_ratio'] = df['monthly_income'] / (df['loan_amount'] + 1)
            
            # 2. ä¿¡ç”¨è¯„åˆ†å½’ä¸€åŒ–ï¼ˆ0-1ï¼‰
            df['credit_score_norm'] = (df['credit_score'] - 300) / 550
            
            # 3. ç»¼åˆé£é™©æŒ‡æ ‡ï¼ˆDTI Ã— ä¿¡ç”¨ï¼‰
            df['dti_credit_risk'] = df['dti_ratio'] * (1 - df['credit_score_norm'])
            
            # 4. æ¯æœˆè¿˜æ¬¾è´Ÿæ‹…
            if 'loan_period_months' in df.columns:
                df['monthly_payment'] = df['loan_amount'] / (df['loan_period_months'] + 1)
                df['payment_income_ratio'] = df['monthly_payment'] / (df['monthly_income'] + 1)
            
            # 5. å¹´é¾„-ä¿¡ç”¨äº¤å‰ç‰¹å¾
            if 'age' in df.columns:
                df['age_credit_interaction'] = df['age'] * df['credit_score_norm']
            
            # 6. èŒä¸šé£é™©å½’ä¸€åŒ–
            df['occupation_risk'] = df['occupation'] / 6.0
            
            # 7. åŸå¸‚å±‚çº§é£é™©ï¼ˆåè½¬ï¼šä¸€çº¿åŸå¸‚é£é™©ä½ï¼‰
            if 'city_tier' in df.columns:
                df['city_risk'] = (4 - df['city_tier']) / 3.0
            
        # Fill NaNs with 0
        df = df.fillna(0)
        
        print(f"âœ… åŠ è½½ç‰¹å¾: {len(df)} è¡Œ, {len(df.columns)} åˆ—")
        return df
    finally:
        conn.close()


def prepare_training_data(
    df: pd.DataFrame, 
    target_col: str = 'target_label',  # Updated default
    test_size: float = 0.2,
    random_state: int = 42
) -> Tuple[pd.DataFrame, pd.DataFrame, pd.Series, pd.Series]:
    """
    å‡†å¤‡è®­ç»ƒæ•°æ® (åˆ†ç¦»ç‰¹å¾å’Œç›®æ ‡,åˆ’åˆ†è®­ç»ƒ/æµ‹è¯•é›†)
    
    Args:
        df: ç‰¹å¾ DataFrame
        target_col: ç›®æ ‡åˆ—å
        test_size: æµ‹è¯•é›†æ¯”ä¾‹
        random_state: éšæœºç§å­
    
    Returns:
        (X_train, X_test, y_train, y_test)
    
    Example:
        >>> X_train, X_test, y_train, y_test = prepare_training_data(df)
    """
    from sklearn.model_selection import train_test_split
    
    # æ£€æŸ¥ç›®æ ‡åˆ—æ˜¯å¦å­˜åœ¨
    if target_col not in df.columns:
        raise ValueError(f"ç›®æ ‡åˆ— '{target_col}' ä¸å­˜åœ¨ã€‚å¯ç”¨åˆ—: {list(df.columns)}")
    
    # åˆ†ç¦»ç‰¹å¾å’Œç›®æ ‡
    X = df.drop(columns=[target_col])
    y = df[target_col]
    
    print(f"ğŸ“Š ç‰¹å¾æ•°: {X.shape[1]}, æ ·æœ¬æ•°: {X.shape[0]}")
    print(f"ğŸ“Š ç›®æ ‡åˆ†å¸ƒ: {y.value_counts().to_dict()}")
    
    # åˆ’åˆ†è®­ç»ƒ/æµ‹è¯•é›†
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=test_size, random_state=random_state
    )
    
    print(f"âœ… è®­ç»ƒé›†: {len(X_train)} æ ·æœ¬, æµ‹è¯•é›†: {len(X_test)} æ ·æœ¬")
    
    return X_train, X_test, y_train, y_test


if __name__ == "__main__":
    import sys
    
    # æµ‹è¯•ç¤ºä¾‹
    if len(sys.argv) > 1:
        duckdb_path = sys.argv[1]
    else:
        duckdb_path = "../../data/warehouse.duckdb"
    
    print(f"ğŸ” æµ‹è¯•ç‰¹å¾åŠ è½½: {duckdb_path}")
    
    try:
        df = load_features(duckdb_path)
        print(f"\nğŸ“‹ æ•°æ®é¢„è§ˆ:\n{df.head()}")
        print(f"\nğŸ“‹ æ•°æ®ç±»å‹:\n{df.dtypes}")
    except Exception as e:
        print(f"âŒ åŠ è½½å¤±è´¥: {e}")
